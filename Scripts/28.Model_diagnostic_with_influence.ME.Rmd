---
title: "28.Model_diagnostic_with_influence.ME"
author: "Christina Raw"
date: "26/4/2022"
output: html_document
---

It seems there is a problem with the lme4 package. When I run the model, it saves it in the environment as <Object with null pointer>. I can run the code chuncks separately, but I can't knit the document as I get the following error "object m4 (the model) not found". I'm making another rmd with images of the outputs.

Since it looked like there were influential observations in the model, in this script I am going to assess the presence of influential observations and groups using the package influence.ME.

## 1. Prepare data set

```{r, warning = FALSE, message = FALSE}
library(influence.ME)
library(readxl)
library(here)
library(tidyverse)
library(robustlmm)

# Load and prepare data set as used to model

d <- read_excel(here("Datasets", "07.Excel_Dataset_to_model_LRR_LONG.xlsx"))

d$Crop <- as.factor(d$Crop)
d$Treatment <- as.factor(d$Treatment)
d$magpie_class <- as.factor(d$magpie_class)
d$Weight <- as.numeric(d$Weight)
d$biodiveristy_metric_category <- as.factor(d$biodiveristy_metric_category)

# Collapse organic and sustainable

d$Treatment[d$Treatment == "Organic"] <- "Sustainable"

# Include monoculture in conventional 

d$Treatment[d$Treatment == "Monoculture"] <- "Conventional"

# Subset agricultural systems with >= 10 observations

treatment_obs <- as.data.frame(table(d$Treatment))
colnames(treatment_obs) <- c("Treatment", "N_Observations")
treatment_obs <- treatment_obs[order(treatment_obs$N_Observations, decreasing = TRUE),]

treatment_obs <- subset(treatment_obs, treatment_obs$N_Observations >= 10)

d <- d[d$Treatment %in% treatment_obs$Treatment, ] 

#Re level data set so conventional is the reference category

d$Treatment <- as.factor(d$Treatment)
d$Treatment <- relevel(d$Treatment, ref = "Conventional")

```

## 2. Model

```{r, eval= FALSE}

m4 <- lmer(LRR ~  Treatment + (1|ID) + (1|Crop), weights = Weight, data = d, control = lmerControl(optimizer ="Nelder_Mead"), na.action = "na.fail")

```

## 3. Test influential data 

I tested for influential data using the package influence.ME and following the tutorial provided by Nieuwenhuis, R., *et al.* (2012) <https://journal.r-project.org/archive/2012/RJ-2012-011/RJ-2012-011.pdf>

To apply detect influential data to generalized mixed effects models, one has to measure the influence of a particular higher level group on the estimates of a predictor measured at that level. The straightforward way is to delete all observations from the data that are nested within a single higher level group, then re-estimate the regression model, and finally evaluate the change in the estimated regression parameters. This procedure is then repeated for each higher-level group separately. The influence function in the influence.ME package performs this procedure automatically, and returns an object containing information on the parameter estimates excluding the influence of each higher level group separately. 

```{r}
estex.m4 <- influence(m4, group = "ID")
```

### DFBETAS

DFBETAS is a standardized measure that indicates the level of influence observations have on single parameter estimates (Fox, 2002). Regarding mixed models, this relates to the influence a higher-level unit has on the parameter estimate. DFBETAS is calculated as the difference in the magnitude of the parameter estimate between the model including and the model excluding the higher level case. 

As a rule of thumb, a DFBETAS cut-off value is given for DFBETAS (Belsley *et al.*, 1980):

$$2 /\sqrt{n}$$
in which *n* refers to the number of groups in the grouping factor under evaluation. Values exceeding this cut-off value are regarded as overly influencing the regression outcomes for that specific estimate.

```{r}

# Obtain dfbetas values

dfbetas <- as.data.frame(dfbetas(estex.m4))

# Obtain dfbetas cutoff value. Dfbetas larger than this value are influential observations

2/sqrt(length(unique(d$ID)))  

# Filter the dfbetas values for influential observations 

influential_dfbetas <- dfbetas %>% filter_all(any_vars(. > 0.1070575))
influential_dfbetas[influential_dfbetas < 0.1070575] <- "NA" 

# Select the columns that have influential data. I do it manually because I don't know the function to do it and I am wasting too much time 

influential_dfbetas <- select(influential_dfbetas, "(Intercept)" , TreatmentConservation,                               TreatmentDisturbed_forest, Treatmentmixed,
                              TreatmentPrimary_vegetation) 

# Plot. The parameters I selected are the treatments that have influential data

plot(estex.m4, which="dfbetas", parameters = c(1, 2, 3, 5, 7), xlab="DFbetaS", ylab="ID")

```

### Cook's distance

The measure of Cook’s distance allows to determine the influence a single higher-level group has on the estimates of multiple variables simultaneously. Cook’s distance provides a sum- mary measure for the influence a higher level unit exerts on all parameter estimates simultaneously, or a selection thereof. Cases are regarded as too influential if the associated value for Cook’s Distance exceeds the cut-off value of: 
$$4 /n$$
in which n refers to the number of groups in the grouping factor under evaluation.

```{r}
# Obtain Cook's distance values

cook <- cooks.distance(estex.m4, sort=TRUE)

# Obtain Cook's distance cutoff values. Values larger than this value are influential observations

4/length(unique(d$ID))

```

```{r, eval = FALSE}
# Cooks distance

plot(estex.m4, which = "cook", cutoff = 0.01146132, sort = TRUE, xlab = "Cook´s Distance", ylab = "Observation ID") 

```

![](Images/Rplot04.png)
### Testing for Changes in Statistical Significance (sigtest)

The sigtest function is used to test for changing levels of significance after deletion of each of the 349 ID groups. In this case I will apply it on the treatments that showed influential data: conventional (intercept), conservation, mixed, disturbed forest and primary vegetation.

```{r}

# Intercept (conventional)

sigtest(estex.m4, test=1.96)$Intercept %>% subset( Changed.Sig == "TRUE")

# Conservation

sigtest(estex.m4, test=1.96)$TreatmentConservation %>% subset(Changed.Sig == "TRUE")

# Mixed

sigtest(estex.m4, test=1.96)$Treatmentmixed %>% subset(Changed.Sig == "TRUE")

# Disturbed forest 

sigtest(estex.m4, test=1.96)$TreatmentDisturbed_forest %>% subset(Changed.Sig == "TRUE")

# Primary vegetation 

sigtest(estex.m4, test=1.96)$TreatmentPrimary_vegetation %>% subset(Changed.Sig == "TRUE")

```


## Robust package

I tried fitting the model using the robustlmm package (Koller, M., 2016) and following the example provied in the reference <https://cran.r-project.org/web/packages/robustlmm/vignettes/rlmer.pdf>. The robustlmm package robustly fits a linear mixed-effects model by fitting a random effects contamination model that accounts for potential contamination on different sources of variability. 

```{r, eval = FALSE}
# Robust model

robust_model <- rlmer(LRR ~  Treatment + (1|ID) + (1|Crop), data = d)

summary(robust_model)
plot(robust_model)

```

### Tuning the fit

the estimates of σ and θ have a low efficiency if the same tuning parameters are used as for estimating the fixed and random effects. To get a higher efficiency, we have to increase the tuning parameter of ρ(σ) e and ρ(σ). We use the update function to fit a model with a higher efficiency for the estimates of σ and θ:

```{r, eval = FALSE}

robust2 <- update(robust_model, rho.sigma.e = psi2propII(smoothPsi, k = 2.28), 
                  rho.sigma.b = psi2propII(smoothPsi, k = 2.28))
```

To fit only the element of θ that corresponds to the “sample” random effect with higher efficiency, we use:

```{r, eval = FALSE}

rsb <- list(psi2propII(smoothPsi), psi2propII(smoothPsi, k = 2.28))
robust3 <- update(robust2, rho.sigma.b = rsb)

```

To compare the estimates of the various fits we did so far, we can use the function compare.

```{r, eval = FALSE}
compare(robust_model, robust2, robust3, show.rho.functions = FALSE)
```

Plot

```{r, eval = FALSE}
plot(robust2)
plot(robust3)

```



